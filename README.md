# Human Detector And Tracker

[![Coverage Report](https://codecov.io/gh/vinay06vinay/Human-Detector-And-Tracker/branch/main/graph/badge.svg)](https://codecov.io/gh/vinay06vinay/Human-Detector-And-Tracker) 
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Build Status](https://github.com/vinay06vinay/Human-Detector-And-Tracker/actions/workflows/run-unit-test-and-upload-codecov.yml/badge.svg)](https://github.com/vinay06vinay/Human-Detector-And-Tracker/actions/workflows/run-unit-test-and-upload-codecov.yml)

## Overview

Perception, Planning, and Controls are the three main components of any autonomous robotics system. Together, these parts enable the robot to see its surroundings, make judgments based on those perceptions, and carry out those decisions to accomplish the objective. In order to incorporate real-time environmental data into the planning algorithm, perception is essential. This project is focused on perception. In particular, it detects and tracks human obstacles in the frame of a monocular camera of a robot.This module will enable the robot to identify the presence of humans and continuously monitor their movements, allowing it to avoid collisions and choose efficient paths in dynamic environments. The primary function of the delivery robot is to transport goods from one location to another, regardless of whether it operates within a confined indoor setting or in an outdoor environment. Human detection is the process of identifying the presence of humans within a given area or image where detection is performed by computer algorithms that analyze the visual data to locate and identify regions or objects by extracting features that represent human figures. Human tracking is the continuous monitoring and recording of the movement and position of one or more humans between frames in a video or in real time video feed by assigning an id to each human. Detecting and tracking humans to prevent collisions stands as the central task for the delivery robot to ensure smooth and safe navigation.

## Team 

1. Neha Nitin Madhekar
2. Rashmi Kapu 
3. Vinay Krishna Bukka

## Phase 0:
In phase 0 we have started with high level design which is the UML and made activity diagram with classes which will be helpful in understanding the project process flow. The details regarding the phase 0 process and implementation are clearly explained through a video which can be accessed through this [link](https://drive.google.com/drive/folders/1tj4G0VvpHVoRTa6DeKy0NeDprOo1u-xy?usp=sharing)
### The proposal document and Quad Chart can be found [here](https://github.com/vinay06vinay/Human-Detector-And-Tracker/tree/main/proposal%20documents)
### The Initial UML Diagrams are found [here](https://github.com/vinay06vinay/Human-Detector-And-Tracker/blob/main/UML%20diagrams/UML_1.pdf)
### The Activity Diagram found [here](https://github.com/vinay06vinay/Human-Detector-And-Tracker/blob/main/UML%20diagrams/Activity_diagram.jpeg)

## Software Practices:
1. [AIP Sheet](https://docs.google.com/spreadsheets/d/1X7TYjea1hpwSc7HJBIq0aZOqBp08vf4WFnDWF-Crw-c/edit?usp=sharing)
2. [Sprint Meeting Notes](https://docs.google.com/document/d/1OUv6qRwsF3ackCCKdnR3cEuVyBTGkZl5UUJlMjFRr8Y/edit?usp=sharing)